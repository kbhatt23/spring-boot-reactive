

Tomcat takes servlet container in spring boot as embeded tomcat server , 
In Spring boot tomcat is embeded, so the max thread can be manipulated in application.properties
	-> server.tomcat.max-threads -> this give thread pool max size -> these threads as part of servlet container(tomcat role) individually serve the request from client
									-> this model is termed as thread per rquest model
	-> This do not mean we give huge size of max thread pool size and win
	-> as each thread have memory in RAM and it can make the performace bad as well if set to large value

so to handle huge request we can use horizontal scaling of apps using kubernetes or contianer orchestration but is costly

so reactive programming try to get away from thread per request model

here we try to create more threads from the main thread and do tasks asynchronously -> hence utilization of resource is increased without increase in cost 	
	-> similiar to asynchronous programming -> non blocking like futures

flow of tech stack in java that try to solve above issue

a. callables : runs in seperate thread , it do not returns anything and also hard to maintain
b. future: runs in seperate thread it returns value , however multiple asynch task can not be done
c. copletalblefuture -> easy to mainitain , same as future but cna handle multiple tasks asynchronously ,functional style and hecne easy to maintain

but c is still tough and can be made better using spring reactive -> easy to use
in completable future there is no back pressure support of data
in reactrive programming there is back pressure support -> eg in reactive data comes like stream/even so each event will have only one item
	this allows the service that calls db to process one by one and help in back pressure support

also there is not good enough error handling support in completable future


This means reactive programming have all feature of completable future + back pressure supports-> allowing consumer to tackle huge data tasks
In JPa complatableFuture<List<ITem>> will be non lbocking but will eventually return all list items at once	
					-> this will make tough for service class to handle and hence no back support
in reactive programming -> it return stream/even one by one

=======Reactive programming also solve issue with DB, 
a. if DB is sending huge data then with traditional API it will crash and there is no communication to tell DB to slow down so that api can handle it
This can be solved using reactive programming -> back pressure compatibility

Issues with old traditional API
a. Can not handle huge concurrent requests.
b. latency is slow
c. Can not handle DB back pressure

best API design approach
a. Async and non blocking features
b. move away from therad per rquest
c. back pressure support in db
d. use fewer threads and utilize them using reactive programming to fullest - > as each thread takes lot of memory

General example in real life scenario:
a. imperative programming -> call > communcation happens only at that time
b. reactive programming -> messaging -> can happen async

Reactive programming is simpilkiar to reactive APIS but are more generic
Data flows and back support is for streams/events in reactive programming howver in reactive API it have back pressure support on db as well

Reactive Stream concepts(part of java 8)==========================

interfaces
a. publisher : this represents data source, it has data stream . 
b. subscriber : this repreent businsess app that wants to access data from publkisher
c. subscription : this is piplein between the above 2
methods:
publisher -> subscribe(Subscriber s)
Subscriber -> onNext(T t) -> gets called n number of times T represent single entry put of n data requested
	 -> onComplete() : gets called at the end success
	 -> onError() - >gets called if any error occurred in subsciber
Subscription -> cancel -> after calling this no event gets triggered from publisher like on next or oncomplete, on error etc
	     -> request(long n) -> start eh cahin, publisher callls subscriber n number of time with individual entries

whole flow
Susbcriber calls subscibe function and pass subscriber object -> publisher sends Subscription object to Subscriber
		-> Subscriber calls cancel or request function of Subscription -> then Publisher calls on next events n number of times
		-> then publisher calls on complete funciton or onerror function o Subscriber

The above specification is generic and is used by a lot of libraries
Means all of them have implementation of above 4 interfaces(Subscriber, Publisher, Subscription , Processor)
libraries eg: 
RX java
project reactor(spring boot default and recommened)
JDK 9 : Flow classes


Testing using assert can be done usingStepverifier in webflux
The exact sequence of events can be verified creating Stepverifier instance

We can combine fluxes in 3 ways:
a. merge : it do in paralle but sequence is not amintained
b. concat : same as merge(runs inb parallel) and sequence is mainied -> slower than merge
c. zip: it is special case when n'th char of each flux is combonecd together
eg -> a,b,c : fluxa
	  d,r,f : fluxb
	  when merged reuslt to ad,br,cf : coding is similar to reduce in streams
	  
we can create infinite series using Flux.interval -> returns long
however subscibe function is non blocking so we can not see the flow
we can limit the infinite series using take method
however even then since subscibe funciton si non blocking the method returns and hence
we wont see the data flowing from infinite series

During testing we can use StepVerifier to have a limited series of inifinite data stream

Stepverifies blocks main thread so we can see data flwoing though the infinite series
Subscribe function is non blocking so can not see data flowing

=====Back Pressure====
back pressure help subscriber to control data flow so that it can handle the load and process without crash. 

Project reactor is both push and pull based system

subscriber pulls the data on need basis sand publisher pushes data as demenaded by subscriber
for eg : in case request in bounded to 4 elements . publisher sends 4 and subscriber pulls
4 entries however there is no cancel event on its own and hence publisher sends further evetns
but subscriber do not pulls them and hecnce cancel event is important in such case

cold flux : normal Flux object is cold flux example
Everytime a subsciber is subscribed to the publisher then everytime it fetches data from
beginining.

Hot Flux : It is object of ConnectableFlux
Everytime a sbscriber is connected to publisher
it picks data from the moment it receives stream entries, no need to start form begininig

for example if we sleep for few seconds after first subscriber starts
and second subscriber about to start then earlier data will be skiped.
eg: stock market publishers

We can use virtualizedtime in step verifer test class to save time for scenarios that tkae huge time
As this could impact build and deployment process

In soring project reactor can be used in 2 set of stacks
a. reactive stack
b. servlet stack

differences
reactive												servlet stack
a Non blocking / async do not wait               a.synchromous , blocking wait
b. Fewer threads and use muti core                  b. One thread per request , Need horiontal scaling
   processors efficiently
   
c.Can be cheaper as horizontal sacling not needed	c. Need horizontal scaling as threads will go out
d. Need reactive security                        d. Need spring security
e. Need netty server reactive                    e . Need servlet container in form of tomcat
f. As of now support for reactive DB            f. canuse nosql or sql using DPA,spring JDBC
like redis, mongo cassandra(nosql) 
	
g. Need spring Webflux for contrrolers            g. Need spring mvc for controller annotation
  annotations	
  
  Two way to implement reactive programing inspring boot
  
  a. annoatated controller:     b. functional web in psring webflux
  
  @restcontroller
  we can just return Flux instance and netty will make browser as non blcking subscriber
  
  by default return type is JSOn whihc makes brwoser as blcking
  We can return JSON/stream media typoe and netty makes browser as non blocking subscriber
  
  While using restcontroller and returning Flux or mono with delay time then since the dfault return is json,
  the subscriber waits for all data to complete
  
  Instead put produces == MediaType.applicaion_stream_json and data will be unblocking
  
   =====functional web in spring webflux=============
  
  In functional web we have two functions that handles the flow
  a. router function : this tackles the request from the client and if mapping exist route to handle function
  		-> router function cna be rleated to @getMapping or @requestmapping annotaion whihc maps the URL to method body
  b. Handler Function : this do the actual processing of processing the request and sending response back to server.
  				- > similar to mehtod body of functiona nnoatated with @requestmapping
  	Handler function needs 2 classes - > ServerReuest -> same as HTTPRequest
  										ServerResponse -> same as HTTPResponse
  										
  										
 
 To test the reactive APIs we can use @webFluxTest annotation on class level, but it scans only ocntroller and restcontroller
 		-> it will help us autowire class WebTestClient that can be used as a client to hit api url
 	to scan and test services and repositories and components we shud use @springboottest
 	The use case of @spring boottest is functional web based project reactor -> handler and router function testing  
 	
 	
 	in spring web flux netty is the default server that is embeded
the netty server is a non blocking server that handles the non blocking apis using event loop architechture


various modules of webflux in proper sequence
a. web client(blocking or with help of netty it cna act as non blocking) 
b. netty server -> acting as embeded non blcking server
c. webflux handler > -> in spring boot it is netty reactor by default: It is used to identify the flux and mono type in request and response.
d. webflux filter -It is filter acting as non blokcing fasion
e. webflux dispatcher handler -> it identifies if the current request is mapped either in controller way(tested using webtestclient and webfluxtest anotation)
					or functional web router way and route it to appropariate handler takes response and revert back to netty server

All these module act in non blocking fashion including security and filterting.

flow of each requeest in springboot webflux design:

web client calls the API -> request goes to netty server -> webflux return flux instance whihc is like a token or promnise quickly
				-> client calls the onsubscribe and rquest(unbounded) calls to the webflux controller
				-> netty returns the even onnext one by one to client 
				-> once all onnext are called it send onCompelte or onError in appropriate case
				-> client can stop the onnext by calling cancel funciton of subscription  which will stop onnext, oncomplete and onError all the events
				
				
Internal working of netty:
Netty is a asynchornoues event driven frmework to handle large number of clients
It is based on single threaded event loop processing multiple connections

Tomcat is different to netty, in tomcat with spring mvc
differences:
a. in tomcat each cleint request is handled by seperate thread,
		in netty it is handled by event loop, event loop is single threaded 
b. tomcat blocks the connection until the whole data is sent back , basically it is blocking in nature
		in netty a promise is sent back to client and hence allowing the connection thread to be used by other client
		hence even with less threads we can handle multiple connections as each connection is processed quickly
		in netty the data event is sent back to client using onnnext event until on complete.
		
Event loop:
Netty has a single threaded process that is ever running. its task is to process any event
An event is anything that clinet needs like create ocnnection , post ata, request for data etc

Task of event loop is to pick event request from event queue and send appropriate action event for that request

similar to node js

Connection between client(non blocking) and netty server is called channel
Each chanel have phases like created active, inactive . Since netty is async chanel is made inactive quickly and data is put in event queue to be processed
by event loop (single threaded)

in webflux we shud always use flux and mono otherwise the event loop will be blocked until the processing of sepcific event and hence
other evetns will go in blocking state, however blocking code can be written as part of completablefutre or future or any new thread
task

everty time chanel is created it must register to event loop , so that future events cna be passed to same chanel only

Event loops are generally gropued together for better productivity
Each event loop has only single thread to run
Ther can be 2 groups of event loop
a. first one is to create new connections , register them to channels , deregister the chanel etc
b. second one is responsible for processing the event queue by sending appropriate event

hence there can be 2 threads per processor for netty server;
total threads in netty serve = 2* number of processor



to run any class in a specific profie: use annotaion @activeProfiles("profile name") -> this will make sure once this class runs active profile is profile name
this is used in test classes of junit 

flatMapMany : can be used to convert mono<x> to flux<Y>
thenMany : Can be used to return Flux if previous function was returning mono
then : if previous is mono we can return mono , if previous is flux then it will return flux

As usual spring boot webflux automatically handles excpetios thrown at any place.
We can use @controllerAdvice and @excepionhandler to send custom error message


========SSE / Real time Streaming events=====

SSE means server sent events or real time streaming service
It means that there iwll be never ending data getting sent from server to client as soon as 
new data comes in reactive DB

Flow in normal reactive programming:
client request for connection -> netty creates a channel and puts data in event loop
-> server returns flux token and connection remains established . -> other event loop
keep on processing it and send onnext , onnext...on complete evenes to clietn 
-> connection is removed form event loop and between client and server

Flow in SSE -> Server side event

There is never a loss in netty channel connection , it keeps on emitting onnext event
as soons as new data comes in reactive DB there will be no onComplete events

mongo DB concepts to implement SSE , real time streaming endpoint
a. tailable cursor : By default mongo db removes connection that process the data to request.
once the whole data is porcessed for the reuqest mongodb rmeoves the connection
This can be used for SSE as connection is never removed between clinet and server.

b. capped collection : Mongo stores data in form of collection
A capped collection is of fixed size , so once more data comes ols is removed.
Itt is similar to que of fixed size.
It retains the insertion order so first inserted is at the top and so on
Once max size is over it removed the oldest one and add new ones.
It can be used for stock ticker and hystrix like streaming

